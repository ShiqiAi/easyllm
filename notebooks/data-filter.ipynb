{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use EasyLLM Quality data filters\n",
    "\n",
    "EasyLLMs `data` package adds quality filters for preprocessing text data for improved pretraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"easyllm[data]\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perplexity filtering\n",
    "\n",
    "Perplexity filtering can be used to improve model quality, coherence, and training efficiency by removing confusing text segments and focusing model learning on more standard, comprehensible language.\n",
    "Perplexity filtering is implemented using `KenLM` models trained on wikipedia. You just need to provide your language id, e.g. `de` and your perplexity `min_threshold` and `max_threshold` the filter will return `True` if the perplexity of the text outside of the threshold `False` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.3\n",
      "46793.5\n"
     ]
    }
   ],
   "source": [
    "from easyllm.data.filters import PerplexityFilter\n",
    "\n",
    "ppl = PerplexityFilter(\"en\",min_threshold=10,max_threshold=1000)\n",
    "\n",
    "# Get perplexity\n",
    "print(ppl.model.get_perplexity(\"I am very perplexed\"))\n",
    "# 341.3 (low perplexity, since sentence style is formal and with no grammar mistakes)\n",
    "\n",
    "print(ppl.model.get_perplexity(\"im hella trippin\"))\n",
    "# 46793.5 (high perplexity, since the sentence is colloquial and contains grammar mistakes)\n",
    "\n",
    "# testing the filter\n",
    "assert ppl(\"I am very perplexed\") == False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NonAlphaNumericFilter\n",
    "\n",
    "The `NonAlphaNumericFilter` removes documents based on the number of non-alphanumeric characters in the document. Based on [Gopher (Rae et al., 2021)](https://arxiv.org/pdf/2112.11446.pdf), if the document has more then 20% non-alphanumeric characters, it is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import NonAlphaNumericFilter\n",
    "\n",
    "nam = NonAlphaNumericFilter()\n",
    "\n",
    "# not filtered\n",
    "assert nam(\"This is a test\") == False\n",
    "\n",
    "# filtered\n",
    "assert nam(\"This is a test!!!!!!!\") == True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SymbolToWordFilter\n",
    "\n",
    "The `SymbolToWordFilter` removes any document with a symbol-to-word ratio greater than 0.1 for either the hash symbol or the ellipsis. Based on [Gopher (Rae et al., 2021)](https://arxiv.org/pdf/2112.11446.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import SymbolToWordFilter\n",
    "\n",
    "stw = SymbolToWordFilter()\n",
    "\n",
    "assert stw(\"This is a test\") == False\n",
    "\n",
    "assert stw(\"spam#spam#spam#spam#spam#spam#spam#spam\") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumbersToCharacterFilter\n",
    "\n",
    "The `NumbersToCharacterFilter` removes any document where the 20% of the document are numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import DigitToCharacter\n",
    "\n",
    "ntw = DigitToCharacter()\n",
    "\n",
    "assert ntw(\"Hello 123 world 456 this text 789 contains 1234 numbers more words\") == False\n",
    "\n",
    "assert ntw(\"Hello 34534 34534 \") == True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UrlRatioFilter\n",
    "\n",
    "The `UrlRatioFilter` removes any document where 20% of the document is a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import UrlRatioFilter \n",
    "\n",
    "ur = UrlRatioFilter()\n",
    "\n",
    "assert ur(\"https://www.google.com\") == True\n",
    "\n",
    "assert ur(\"Example text with some urls http://www.example.com and more text https://www.example2.com and more text\") == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BulletpointRatioFilter \n",
    "\n",
    "The `BulletpointRatioFilter` removes documents that have more than 90% bulletpoints. Based on [Gopher (Rae et al., 2021)](https://arxiv.org/pdf/2112.11446.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import BulletpointRatioFilter\n",
    "\n",
    "br = BulletpointRatioFilter()\n",
    "\n",
    "assert br(\"This is a text with \\n- some bullets but\\nnot all\") == False\n",
    "\n",
    "assert br(\"- some bullets and\\n- some more\") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WhitespaceRatioFilter\n",
    "\n",
    "The `WhitespaceRatioFilter` is a filter that removes documents that more than 25% of the text is whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import WhitespaceRatioFilter\n",
    "\n",
    "wr = WhitespaceRatioFilter()\n",
    "\n",
    "assert wr(\"This is a test\") == False\n",
    "\n",
    "assert wr(\"Hello world!      This text has    extra whitespace.\") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParenthesesRationFilter\n",
    "\n",
    "The `ParenthesesRationFilter` is a filter that removes all sentences that have a parentheses ratio greater than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import ParenthesesRationFilter\n",
    "\n",
    "pr = ParenthesesRationFilter()\n",
    "\n",
    "assert pr(\"This is a normal sentence\") == False\n",
    "\n",
    "assert pr(\"This a (with ) ] {(e)\") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LongWordFilter\n",
    "\n",
    "The `LongWordFilter` is a filter that removes documents that include words longer > 1000 character, e.g. js minfied files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyllm.data.filters import LongWordFilter\n",
    "\n",
    "lw = LongWordFilter()\n",
    "\n",
    "assert lw(\"This is a test\") == False\n",
    "\n",
    "assert lw(f\"This is a test with a {'longword'*500}\") == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
